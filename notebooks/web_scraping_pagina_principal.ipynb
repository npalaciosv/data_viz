{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Web Scraping de TUCARRO.COM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Importamos las respectivas librer√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Hacemos el respectivo requerimiento a la p√°gina**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Necesitamos un indicador que nos diga si la conexion fue realmente efectiva, en este caso, **200** es el c√≥digo que muestra una conexion exitosa.\n",
    "\n",
    "üóíÔ∏è **Observaci√≥n:** Para una mayor informacion, les dejo el siguiente link üîó https://developer.mozilla.org/es/docs/Web/HTTP/Status/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = requests.get('https://carros.tucarro.com.co/')\n",
    "print(html_text.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Convertimos la pagina que vamos a scrapear en una variable para poder usarla luego como un registro de donde esta saliendo la informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexion_url = html_text.url\n",
    "print(conexion_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Seleccionamos la grilla espec√≠fica de donde vamos a sacar la informaci√≥n**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è La informacion que necesitamos esta contenida en el siguiente elemento HTML *'ui-search-layout ui-search-layout--grid'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_text.text, 'lxml')\n",
    "cars_grill = soup.find('ol', class_ = 'ui-search-layout ui-search-layout--grid')\n",
    "cars = cars_grill.find_all('li', class_ = 'ui-search-layout__item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Extraemols la informaci√≥n correspondiente**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Necesitamos guardar la informacion que vamos a extraer de la p√°gina web. Para esta aplicacion, vamos a usar la memoria del sistema para almancenar los datos a traves de un dataframe.\n",
    "\n",
    "üóíÔ∏è **Observaci√≥n:** Una aplicaci√≥n real requiere montar un back-end donde la informaci√≥n persista una vez es descargada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaramos un datafram vacio en el cual vamos a guardar la informacion posteriormente\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Nombre del carro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Iniciamos a iterarar para buscar cada uno de los elementos que necesitamos encontrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una lista vacio donde vamos a almacenar la informacion\n",
    "car_name_list = []\n",
    "\n",
    "for car in cars:\n",
    "    car_name = car.find('img', alt = True)\n",
    "    \n",
    "    #Construimos las expresi√≥n regular para identificar el nombre del carro\n",
    "    pattern = r'<img[^>]*alt=\"([^\"]*)\"'\n",
    "    car_name_adjusted = re.findall(pattern, str(car_name))\n",
    "    car_name_list.append(car_name_adjusted)\n",
    "\n",
    "df = pd.DataFrame(car_name_list, columns=['Nombre_del_vehiculo'])\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Precio del carro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una lista vacio donde vamos a almacenar la informacion\n",
    "price_car_list = []\n",
    "\n",
    "for car in cars:\n",
    "    price_car = car.find('span', class_ = 'andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript')\n",
    "\n",
    "    #Construimos las expresi√≥n regular para identificar el precio\n",
    "    pattern = r'aria-label=\"(\\d+)'\n",
    "\n",
    "    price_car_adjusted = re.findall(pattern, str(price_car))\n",
    "    price_car_adjusted = int(price_car_adjusted[0])\n",
    "    price_car_list.append(price_car_adjusted)\n",
    "\n",
    "df['Precio_del_vehiculo'] = price_car_list\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Model y Kilometraje del carro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una lista vacio donde vamos a almacenar la informacion\n",
    "model_car_list = []\n",
    "km_car_list = []\n",
    "\n",
    "for car in cars:\n",
    "    # Extraemos el modelo del carro\n",
    "    model_car = int(car.find_all('li', class_ = 'ui-search-card-attributes__attribute')[0].text)\n",
    "    model_car_list.append(model_car)\n",
    "\n",
    "    # Extraemos el kilometraje del carro\n",
    "    km_car = car.find_all('li', class_ = 'ui-search-card-attributes__attribute')[1].text\n",
    "    km_car = int(km_car.replace(\" Km\",\"\").replace(\".\",\"\"))\n",
    "    km_car_list.append(km_car)\n",
    "\n",
    "df['Modelo_del_vehiculo'] = model_car_list\n",
    "df['Kilometraje_del_vehiculo'] = km_car_list\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Ubicaci√≥n del carro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una lista vacio donde vamos a almacenar la informacion\n",
    "location_car_list = []\n",
    "\n",
    "for car in cars:\n",
    "    location_car = car.find('span', class_ = 'ui-search-item__group__element ui-search-item__location').text\n",
    "    location_car_list.append(location_car)\n",
    "\n",
    "df['Ubicacion_del_vehiculo'] = location_car_list\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una lista vacio donde vamos a almacenar la informacion\n",
    "links_car_list = []\n",
    "\n",
    "for car in cars:\n",
    "    link_car = car.find('a', class_ = 'ui-search-link')['href']\n",
    "    links_car_list.append(link_car)\n",
    "\n",
    "df['link'] = links_car_list\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Marca del vehiculo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Aun no sabemos la marca del veh√≠culo, necesitamos extraerla de la columna *'Nombre_del_vehiculo'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Marca_del_vehiculo'] = df['Nombre_del_vehiculo'].str.split(\" \").str[0]\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Timestand de la operacion y metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Es importante que siempre haya un registro historico de las operaciones para efectos de trazabilidad. Otra metadata que podriamos agregar es la pagina de la que se esta extrayendo la informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Registro_pagina_principal'] = pd.Timestamp.now()\n",
    "df['origen_general'] = conexion_url\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üóíÔ∏è **Observaci√≥n:** En este punto podemos usar las propiedades de tablas SQL para vincular la informacion general que se est√° extrayendo en este punto, con la que vamos a extraer posteriormente para cada uno de los items.\n",
    "\n",
    "Para tal efecto, necesitamos tener una llave que una ambas tablas, y en este caso, la llave es el identficador de cada veh√≠culo que aparece en la url y que inicia con MCO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mco_code(url):\n",
    "    import re\n",
    "    pattern = r'MCO-\\d+'\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        return match.group().replace('-', '')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['Key'] = df['link'].apply(extract_mco_code)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Identificamos las p√°ginas que vamos a consultar**\n",
    "\n",
    "‚û°Ô∏è Para este ejercicio vamos a consultar unicamente las primeras 10 paginas disponibles. Vamos primero a declarar un diccionario que nos ayude a documentar las paginas en las que nos vamos a mover, la inicial termina con sufijo **\"/_NoIndex_True\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paginas = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Podemos observar que cada pagina tiene 48 elementos, y que la segunda pagina arranca en *\"49 - _Desde_49_NoIndex_True\"*, la tercera en *97 - _Desde_97_NoIndex_True*, es decir con 48 elementos de diferencia... ü§Ø **\"hay est√° el patr√≥n\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    if i == 1:\n",
    "        paginas[str(i)] = f'_NoIndex_True'\n",
    "    else:\n",
    "        paginas[str(i)] = f'_Desde_{48*(i-1)+1}_NoIndex_True'\n",
    "    print(paginas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scrapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
